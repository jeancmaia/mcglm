<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>teste</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="teste_files/libs/clipboard/clipboard.min.js"></script>
<script src="teste_files/libs/quarto-html/quarto.js"></script>
<script src="teste_files/libs/quarto-html/popper.min.js"></script>
<script src="teste_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="teste_files/libs/quarto-html/anchor.min.js"></script>
<link href="teste_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="teste_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="teste_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="teste_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="teste_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">teste</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>The Multivariate Covariance Generalized Linear Model (MCGLM) is a universalization of the classic statistical model GLM, widening for multivariate and non-independent response fitting. Due to its pliancy and explicit specification, this unified model can support many statistical analyses on a wide variety of data and distinct traits. Aiming to foment the pervasiveness of statistical analysis with MCGLM support, this essay instills MCGLM and its comprehensive new Python library - the <code>mcglm</code>. The library is hosted on PyPI and can be installed with the aid of some Python library manager, such as pip. https://pypi.org/project/mcglm/.</p>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>Dated at the beginning of the 19th century and controversial about actual authorship, the least squares method established an optimization proposal <code>[1]</code>. According to the Gauss-Markov theorem <code>[2]</code>, the resulting estimates are optimal and unbiased under linear conditions of continuous values. This optimization method is leveraged by <code>linear regression</code>, one of the primordial statistical models <code>[3]</code>, <code>[4]</code>. A linear regression associates a response variable to a group of covariates by employing a linear operation on regression parameters <code>[5]</code>. Three main assumptions for linear regression are linearity, independent realizations of the response variable, and a gaussian homoscedastic error with a zero mean. Aiming to generalize it, some subsequential statistical proposals expanded these assumptions.</p>
<p>The Generalized Linear Model (GLM) <code>[6]</code> generalizes the gaussian assumption of linear regression to some models of the exponential family <code>[7]</code>; The Generalized Additive Model (GAM) <code>[8]</code> manages regression by the sum of smooth operations on covariates; The Generalized Estimating Equations (GEE) <code>[9]</code> applies the quasi-likelihood estimating functions to adjust longitudinal data; Copulas <code>[10]</code>, <code>[11]</code> and Mixed Models <code>[12]</code> are consolidated models that can fit non-independent response data, to cite a few. Amid the most recent postulations resides the family of Multivariate Covariance Generalized Linear Models (MCGLM).</p>
<p>The Multivariate Covariance Generalized Linear Model (MCGLM) <code>[13]</code> universalizes GLM by allowing the multivariate analysis of non-independent responses, such as longitudinal and spatial data. This versatility is the main trait of MCGLM; it stems from two-moment assumptions and the specification of its five fundamental components: linear predictor via design matrix, link function, variance function, covariance link function, and the linear matrix predictor through Z matrices. The model allows the assessment of regression coefficients and dispersion parameters, hypothesis tests, goodness-of-fit measurements, and correlation coefficients between outcome variables.</p>
<p>Refs:</p>
<p>[1] Stigler SM (1981). “Gauss and the Invention of Least Squares.” The Annals of Statistics, 9(3), 465 – 474. doi:10.1214/aos/1176345451. URL https://doi.org/10.1214/aos/1176345451<br>
[2] Hallin M (2014). Gauss–Markov Theorem in Statistics. ISBN 9781118445112. doi:10.1002/9781118445112.stat07536.<br>
[3] Narula SC, Wellington JF (1982). “The Minimum Sum of Absolute Errors Regression: A State of the Art Survey.”<br>
[4] Galton F (1886). “Regression towards mediocrity in hereditary stature.” Journal of the Anthropological Institute of Great Britain and Ireland, pp.&nbsp;246–263.<br>
[5] Seal HL (1967). “Studies in the History of Probability and Statistics. XV: The Historical Development of the Gauss Linear Model.” Biometrika, 54(1/2), 1–24. ISSN 00063444. URL http://www.jstor.org/stable/2333849.<br>
[6] Nelder J, Wedderburn R (1972). “Generalized Linear Models.” pp.&nbsp;370–384. doi:https://doi.org/10.2307/2344614.<br>
[7] M ̈uller M (2004). “Generalized Linear Models.” doi:10.1007/978-3-642-21551-3_24.<br>
[8] Hastie T, Tibshirani R (1986). “Generalized additive models (with discussion).” Statistical Science 1, p.&nbsp;297–318.<br>
[9] Liang KY, Zeger SL (1986). “Longitudinal Data Analysis Using Generalized Linear Models.” Biometrika, 73(1), 13–22.<br>
[10] Krupskii P, Joe H (2013). “Factor Copula Models for Multivariate Data.” Journal of Multivariate Analysis, 120(1), 85–101.<br>
[11] Masarotto G, Varin C (2012). “Gaussian Copula Marginal Regression.” Electronic Journal of Statistics, 6, 1517–1549.<br>
[12] Verbeke G, Fieuws S, Molenberghs G, Davidian M (2014). “The Analysis of Multivariate Longitudinal Data: A Review.” Statistical Methods in Medical Research, 23(1), 42–59.<br>
[13] Bonat WH, Jørgensen B (2016). “Multivariate Covariance Generalized Linear Models.” Journal of the Royal Statistical Society C, 65(5), 649–675. doi:10.1111/rssc.12145.</p>
</section>
<section id="statistical-models-and-a-brief-literary-review." class="level3">
<h3 class="anchored" data-anchor-id="statistical-models-and-a-brief-literary-review.">Statistical models and a brief literary review.</h3>
<p>To develop intuition on statistical models, we dissect classical linear regression. According to McCullagh, P and Nelder, J.A, 1989 in their fantastic book “Generalized Linear Models”, yet rephrased by myself, an enthusiast disciple, a linear regression can be decomposed into two components: <code>systematic</code> and <code>random</code> parts.</p>
<p>Assuming an outcome variable <span class="math inline">\(\boldsymbol{y}\)</span> with <span class="math inline">\(n\)</span> components considered independent realizations of a random variable <span class="math inline">\(\boldsymbol{Y}\)</span>. There is a vector <span class="math inline">\(\boldsymbol{\mu}\)</span> which holds the mean parameters of those realizations. The systematic part of the model specifies the vector <span class="math inline">\(\boldsymbol{\mu}\)</span> by employing a linear operation between regression parameters <span class="math inline">\(\beta_0,...,\beta_p\)</span> and the covariates. The mathematical notation for the systematic part:</p>
<p><span class="math display">\[\begin{equation*}
    \mathrm{E}(Y_i) =  
    \mathrm{\mu_i} =
    \beta_0 +
    \sum_{j=1}^{p} x_{ij}\beta_j;\qquad i = 1,...,n.
    %\mathrm{V}(\boldsymbol{\mu}_r;p_r)^{\frac{1}{2}} (\boldsymbol{\Omega}(\boldsymbol{\tau}_r))
    %\mathrm{V}(\boldsymbol{\mu}_r;p_r)^{\frac{1}{2}}.
  \end{equation*}\]</span></p>
<p>where <span class="math inline">\(x_{ij}\)</span> is the value of the jth covariate for observation <span class="math inline">\(i\)</span>.</p>
<p>Moreover, as the random part, we assume independence and constant variance of errors. These errors follow a Gaussian distribution with mean 0 and constant variance <span class="math inline">\(\sigma^2\)</span> - giving to linear regression the adjective <code>Homoscedasticity</code>.</p>
<p>For a simple linear regression, the model graphically shapes as the image below:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="linear_regression.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">title</figcaption><p></p>
</figure>
</div>
<p>As a statistical model, linear regression associates a response variable with at least one explanatory variable.</p>
<p>In 1972, Nelder and Wedderburn went a step further in unifying the theory of statistical modeling and, in particular, regression models, publishing their article on generalized linear models (GLM).</p>
<p>In the context of GLM, each component of the random variable <span class="math inline">\(Y\)</span> assumes a distribution in the <code>exponential family</code>, in which the probability or density function takes the form.</p>
<p><span class="math display">\[\begin{equation*}
    \mathrm{f}_y(y;\theta,\phi) =
    \mathrm{exp\{(y\theta - b(\theta))/a(\phi) + c(y,\phi)\}}
\end{equation*}\]</span></p>
<p>for some specific functions <span class="math inline">\(a(\phi)\)</span>, <span class="math inline">\(b(\theta)\)</span> and <span class="math inline">\(c(y,\phi)\)</span>. Mean and Variance can be specified as:</p>
<p><span class="math display">\[\begin{equation*}
    \mathrm{E}(Y) = b'(\theta).\qquad
    \mathrm{Var}(Y) = b''(\theta)a(\phi).
\end{equation*}\]</span></p>
<p>A couple of possible models in this framework:</p>
<span class="math display">\[\begin{array}{lll} \hline
    \text{Distribution}  &amp; \text{Support} &amp; \text{Cases} \\ \hline
    \text{Gaussian}  &amp; \text{Real Numbers} &amp; \text{General Symmetric Distributions.} \\
    \text{Binomial(Bernoulli)}  &amp; \text{Bounded Data} &amp; \text{Probability/Odds of an event.} \\
    \text{Poisson}  &amp; \text{Integer Positive} &amp; \text{Positive Count Distributions.} \\
    \text{Gamma}  &amp; \text{Real Positive Numbers} &amp; \text{Positive Asymmetric Distributions.} \\
    \text{Inverse Gaussian} &amp; \text{Real Positive Numbers} &amp; \text{Positive Asymmetric Distributions.} \\ \hline
\end{array}\]</span>
<p>GLM relies on three components: A design matrix with covariates, a link function, some distribution of exponential family or a variance function. The usual choices for the link and variance functions.</p>
<span class="math display">\[\begin{array}{lll} \hline
    \text{Distribution}  &amp; \text{Canonical link function} &amp; \text{Variance function} \\ \hline
    \text{Poisson}     &amp; \text{Log} &amp; \text{$\mu$} \\
    \text{Binomial}    &amp; \text{Logit} &amp; \text{$\mu(\mu - 1)$} \\
    \text{Normal}  &amp; \text{Identity} &amp; \text{1} \\
    \text{Gamma}  &amp; \text{Reciprocal} &amp; \text{$\mu^2$} \\
    \text{Inverse Gaussian}  &amp; \text{Reciprocal²} &amp; \text{$\mu^3$} \\ \hline
\end{array}\]</span>
<p>The <code>maximum-likelihood</code> estimator leverages the underlying distribution to find regression coefficients and dispersion estimates that maximize the product of likelihood. Therefore, two assumptions of GLM are: linearity upon the link function and random variable <span class="math inline">\(Y\)</span> is independently distributed as some exponential family distribution. The figure below illustrates the <code>Binomial</code> and <code>Poisson</code> models.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="regressao_binomial.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">title</figcaption><p></p>
</figure>
</div>
<table class="table">
<colgroup>
<col style="width: 4%">
</colgroup>
<tbody>
<tr class="odd">
<td><img src="regressao_poisson.png" class="img-fluid" alt="title"></td>
</tr>
</tbody>
</table>
<p>Stepping ahead two years, Wedderburn, one of the authors of GLM, published in 1974 one of the most iconic papers of history. “Quasi-Likelihood Functions, Generalized Linear Models, and the Gauss-Newton Method”. He proposed a relative likelihood estimator, the <code>quasi-likelihood</code>, which does not rely on a distribution model, yet provides asymptotically unbiased and consistent estimators. As long as statisticians cannot know the distribution upfront, the <code>quasi-likelihood</code> play an essential role in statistical models. The <code>quasi-score</code> is an <code>Estimating Equation</code> for quasi-likelihood functions.</p>
<hr>
<p>In 1986, Liang and Zeger published the paper “Longitudinal data analysis using generalized linear models”, which establishes an extension of Generalized Linear Models (GLM) to longitudinal data analysis. The paper epitomizes that data scenario.</p>
<pre><code>The severity of respiratory disease, along with the nutritional status, age, and family income of children, might be observed once every three months for 18 months. The dependence of the outcome variable, severity of disease, on the covariates is of interest.</code></pre>
<p>The paper introduces an <code>Estimating Equation</code> that gives consistent estimates of the regression coefficients and their variances under weak assumptions about the joint distribution, the model GEE. The dispersion parameters remain a nuisance. The model harnesses the correlation matrix to define the dependence between components of the response variable. Furthermore, the paper suggests some dependences structures for GEE: <code>independent</code>, <code>autoregressive</code>, <code>exchangeable</code>, <code>unstructured</code>, <code>stationary-M</code>, <code>M-dependent</code>, or <code>non-stationary</code>. The GEE relies on the specification of four components: design matrix with covariates; link function; variance function; correlation matrix.</p>
<p>Finally, in 2016, Bonat and Jørgensen published the MCGLM, A brand new family of Statistical Models: Multivariate Covariance Generalized Linear Models.</p>
</section>
<section id="mcglm" class="level3">
<h3 class="anchored" data-anchor-id="mcglm">MCGLM</h3>
<p>The two-moment assumptions entail distinct apparatus for mean and variance. The optimization process of MCGLM blends two second-order optimization algorithms, the <code>Fisher Scoring</code> <code>[14]</code>, <code>[15]</code> for regression, and <code>Chaser</code> <code>[16]</code> for dispersion parameters in tandem. Moreover, the estimating functions <code>Quasi-score</code> <code>[17]</code> and <code>Pearson Estimating Equation</code> are leveraged for the first and second moment, respectively.</p>
<p>Let <span class="math inline">\(\mathbf{Y}_{N \times R} = \{\boldsymbol{Y}_1, \ldots, \boldsymbol{Y}_R\}\)</span> be a response matrix, and <span class="math inline">\(\mathbf{M}_{N \times R} = \{\boldsymbol{\mu}_1, \ldots, \boldsymbol{\mu}_R\}\)</span> denote the corresponding matrix of expected values. Let <span class="math inline">\(\boldsymbol{\Sigma}_r\)</span> the <span class="math inline">\(N \times N\)</span> variance-covariance matrix of the outcome <span class="math inline">\(r\)</span>, for <span class="math inline">\(r = 1, \ldots, R\)</span>. Similarly, let <span class="math inline">\(\boldsymbol{\Sigma}_b\)</span> be a <span class="math inline">\(R \times R\)</span> correlation matrix inter responses. Let <span class="math inline">\(\boldsymbol{X}_r\)</span> denote an $N k_r $ design matrix and <span class="math inline">\(\boldsymbol{\beta}_r\)</span> a <span class="math inline">\(k_r \times 1\)</span> regression parameter vector. The two-moment specification of the MCGLM model goes as it follows:</p>
<p><span class="math display">\[\begin{equation*}
\mathrm{E}(\mathbf{Y}) = \mathbf{M} = \{g_1^{-1}(\boldsymbol{X}_1 \boldsymbol{\beta}_1), \ldots, g_R^{-1}(\boldsymbol{X}_R \boldsymbol{\beta}_R)\}
\end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*}
\mathrm{Var}(\mathbf{Y}) = \boldsymbol{C} = \boldsymbol{\Sigma}_R \overset{G} \otimes \boldsymbol{\Sigma}_b
\end{equation*}\]</span></p>
<p>where the <span class="math inline">\(C\)</span> leverages the generalized Kronecker product <span class="math inline">\(\boldsymbol{\Sigma}_R \overset{G} \otimes \boldsymbol{\Sigma}_b = \mathrm{Bdiag}(\tilde{\boldsymbol{\Sigma}}_1, \ldots, \tilde{\boldsymbol{\Sigma}}_R)(\boldsymbol{\Sigma}_b \otimes \boldsymbol{I})\mathrm{Bdiag}(\tilde{\boldsymbol{\Sigma}}_1^T, \ldots, \tilde{\boldsymbol{\Sigma}}_R^T)\)</span> <code>[18]</code>. The matrix <span class="math inline">\(\tilde{\boldsymbol{\Sigma}}_r\)</span> denotes a low triangular Cholesky decomposition of <span class="math inline">\(\boldsymbol{\Sigma}_r\)</span>. The operator <span class="math inline">\(\mathrm{Bdiag}\)</span> denotes a block diagonal matrix and <span class="math inline">\(\boldsymbol{I}\)</span> denotes an <span class="math inline">\(N \times N\)</span> identity matrix. Regarding the mean, or expectation, operation <span class="math inline">\(g_r(\cdot)\)</span> is a usual link function from GLM. <span class="math inline">\(\boldsymbol{\Sigma}_r\)</span> is defined by:</p>
<p><span class="math display">\[\begin{equation*}
\boldsymbol{\Sigma}_r =
\mathrm{V}(\boldsymbol{\mu}_r;p_r)^{\frac{1}{2}} (\boldsymbol{\Omega}(\boldsymbol{\tau}_r))
\mathrm{V}(\boldsymbol{\mu}_r;p_r)^{\frac{1}{2}},
\end{equation*}\]</span> where <span class="math inline">\(\mathrm{V}(\boldsymbol{\mu}_r;p_r) = \mathrm{diag}(\vartheta(\boldsymbol{\mu}_r;p_r))\)</span> is a diagonal matrix, whose main entries are the variance function applied on the expected values <span class="math inline">\(\boldsymbol{\mu_r}\)</span>. Each variance function establishes its unique marginal distributions on MCGLM. Furthermore, MCGLM leverages linear matrix predictor with covariance link function for dispersion matrix definition <code>[19]</code>, <code>[20]</code>, <code>[21]</code>. <span class="math display">\[\begin{equation}
h(\boldsymbol{\Omega}(\boldsymbol{\tau}_r)) = \tau_{r0} Z_{r0} + \cdots + \tau_{rD} Z_{rD},
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\mathrm{h(\cdot)}\)</span> is the covariance link function and matrices <span class="math inline">\(Z_r\)</span> specifies the dependence inner response. The main article details many structures that can be fitted through linear matrix predictor.</p>
<p>As the mathematical notation alludes, it is up to the user to pick their choices for the link, variance, covariance functions, and dependence matrices.</p>
<p>Refs:</p>
<p>[14] Jennrich RI (1969). “A Newton-Raphson algorithm for maximum likelihood factor analysis.” Psychometrika, 34. ISSN 1860-0980. doi:10.1093/biomet/61.3.439. URL https://doi.org/10.1007/BF02290176.<br>
[15] Widyaningsih P, Saputro D, Putri A (2017). “Fisher Scoring Method for Parameter Estimation of Geographically Weighted Ordinal Logistic Regression (GWOLR) Model.” Journal of Physics: Conference Series, 855, 012060. doi:10.1088/1742-6596/855/1/012060<br>
[16] Jørgensen B, Knudsen SJ (2004). “Parameter Orthogonality and Bias Adjustment for Estimating Functions.” Scandinavian Journal of Statistics, 31(1), 93–114.<br>
[17] Wedderburn RWM (1974). “Quasi likelihood functions, generalized linear models, and the Gauss—Newton method.” Biometrika, 61(3), 439–447. ISSN 0006-3444. doi:10.1093/biomet/61.3.439. https://academic.oup.com/biomet/article-pdf/61/3/439/690500/61-3-439.pdf, URL https://doi.org/10.1093/biomet/61.3.439.<br>
[18] Martinez-Beneito MA (2013). “A General Modelling Framework for Multivariate Disease Mapping.” Biometrika, 100(3), 539–553.<br>
[19] Anderson TW (1973). “Asymptotically Efficient Estimation of Covariance Matrices with Linear Structure.” The Annals of Statistics, 1(1), 135–141.<br>
[20] Pourahmadi M (2000). “Maximum Likelihood Estimation of Generalized Linear Models for Multivariate Normal Covariance Matrix.” Biometrika, 87(2), 425–435.<br>
[21] Bonat WH (2016). “Modelling Mixed Outcomes in Additive Genetic Models.” ArXiv.</p>
</section>
<section id="mcglm-components" class="level3">
<h3 class="anchored" data-anchor-id="mcglm-components">MCGLM components</h3>
<p>The variance function is fundamental to the MCGLM, as it defines the marginal distribution of a response variable. To highlight some common choices, the variance function <code>power</code> specializes in handling continuous data and is fundamental to the <code>Tweedie</code> family of distribution models. According to <code>[23]</code> and <code>[24]</code>, this family has its emblematic cases: <code>Gaussian</code> (p = 0), <code>Gamma</code> (p = 2), and <code>Inverse Gaussian</code> (p = 3). The variance function <code>extended binomial</code> is a common choice for analyzing limited data. For the adjustment of count data, the dispersion function presented by <code>[25]</code>, called <code>Poisson-Tweedie</code>, is flexible to capture notable models, such as: <code>Hermite</code> (p = 0), <code>Neyman Type A</code> (p = 1), <code>Negative Binomial</code> (p = 2) and <code>Gaussian Poisson-inverse</code> (p = 3). The following table summarizes the variance functions cited:</p>
<span class="math display">\[\begin{array}{ll} \hline
    \text{Function name}  &amp; \text{Formula} \\ \hline
    \text{power/Tweedie}  &amp; \mathrm{V}(p) = \mu^{p}  \\
    \text{binomial}  &amp; \mathrm{V}(p) = \mu^{p} (1 - \mu_r)^{p} \\
    \text{Poisson-Tweedie}  &amp; \mathrm{V}(p) = \mu + \tau\mu_{p}  \\  \hline
\end{array}\]</span>
<p>The covariance link function <span class="math inline">\(h(\cdot)\)</span> is described by . To cite a few examples: <code>identity</code>, <code>inverse</code> and <code>exponential-matrix</code> <code>[22]</code>.</p>
<p>In MCGLM, the user specifies the dependency through dependency matrices <code>Z</code>, supporting the flexible profile of the model. Many classical statistical models are replicable by specifying <code>Z</code> matrices. To cite a few, mixed models, moving averages and compound symmetry. For in-deep details, see <code>[13]</code>.</p>
<p>Refs:<br>
[22] Chiu TYM Leonard T TK (1996). “The Matrix-Logarithmic Covariance Model.” Journal of the American Statistical Association. doi:10.1080/01621459.1996.10476677.<br>
[23] Jørgensen B (1987). “Exponential dispersion models.” Journal of the Royal Statistical Society.<br>
[24] Jørgensen B (1997). “The theory of dispersion models.” CRC Press.<br>
[25] Jørgensen B, Kokonendji CC (2015). “Discrete dispersion models and their tweedie asymptotics.” AStA Advances in Statistical Analysis, 100(1), p.&nbsp;43–78.</p>
<p>The brand new library <code>mcglm</code>.</p>
<p>The Python library <code>mcglm</code> provides an easy interface for fitting the MCGLM model, similar to the library <code>statsmodels</code>, providing auxiliary methods to lead a proper specification of each MCGLM component. The library provides a comprehensive report for the model fitting analysis with regression coefficients, dispersion estimates, confidence intervals, hypothesis testing, and Pearson residuals. Only R users have access to the MCGLM algorithm by the package <code>mcglm</code>.</p>
<p>Finally, this notebook presents some statistical analysis with the support of Python <code>mcglm</code>.</p>
<p>Refs:</p>
<p>https://www.jstor.org/stable/44681850<br>
https://www.researchgate.net/publication/324579147_Multiple_Response_Variables_Regression_Models_in_R_The_mcglm_Package</p>
</section>
<section id="modeling-time" class="level3">
<h3 class="anchored" data-anchor-id="modeling-time">Modeling time</h3>
<div class="cell" data-tags="[]" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>sys.path.append(os.path.join(sys.path[<span class="dv">0</span>], <span class="st">".."</span>))</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mcglm <span class="im">import</span> MCGLM, mc_mixed, mc_id, mc_ma</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> patsy <span class="im">import</span> dmatrix</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.tools.tools <span class="im">import</span> add_constant</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.tsa.seasonal <span class="im">import</span> seasonal_decompose</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.tsa.stattools <span class="im">import</span> adfuller</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.tsa.arima_process <span class="im">import</span> ArmaProcess</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>warnings.simplefilter(<span class="st">"ignore"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-tags="[]" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># library docstring.</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(MCGLM.__doc__)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
    MCGLM class that implements MCGLM stastical models. (Bonat, Jørgensen 2015)
        
    It extends GLM for multi-responses and dependent components by fitting second-moment assumptions.

    Parameters
    ----------
    endog : array_like
        1d array of endogenous response variable. In case of multiple responses, the user must pass the responses on a list.  
    exog : array_like
        A dataset with the endogenous matrix in a Numpy fashion. Since the library doesn't set an intercept by default, the user must add it. In the case of multiple responses, the user must pass the design matrices as a python list. 
    z : array_like
        List with matrices components of the linear covariance matrix.
    link : array_like, string or None
        Specification for the link function. The MCGLM library implements the following options: identity, logit, power, log, probit, cauchy, cloglog, loglog, negativebinomial. In the case of None, the library chooses the identity link. In multiple responses, user must pass values as list.  
    variance : array_like, string or None
        Specification for the variance function. The MCGLM library implements the following options: constant, tweedie, binomialP, binomialPQ, geom_tweedie, poisson_tweedie. In the case of None, the library chooses the constant link. In multiple responses, user must pass values as list.   
    offset : array_like or None
        Offset for continuous or count. In multiple responses, user must pass values as list.   
    Ntrial : array_like or None
        Ntrial for binomial responses. In multiple responses, user must pass values as list.
    power_fixed : array_like or None
        Parameter that allows estimation of power when variance functions is either tweedie, geom_tweedie or poisson_tweedie. In multiple responses, user must pass values as list. 
    maxiter : float or None
        Number max of iterations. Defaults to 200.
    tol : float or None
        Threshold of minimum absolute change on paramaters. Defaults to 0.0001.
    tuning : float or None
        Step size parameter. Defaults to 0.5.
    weights : array_like or None
        Weight matrix. Defaults to None.
        
    Examples
    ----------
    &gt;&gt;&gt; import statsmodels.api as sm
    &gt;&gt;&gt; data = sm.datasets.scotland.load()
    &gt;&gt;&gt; data.exog = sm.add_constant(data.exog)
    
    &gt;&gt;&gt; model = sm.GLM(data.endog, data.exog, z=[mc_id(data.exog)],
    ...                      link="log", variance="tweedie",
    ...                      power=2, power_fixed=False)
    
    &gt;&gt;&gt; model_results = model.fit()
    &gt;&gt;&gt; model_results.mu
    &gt;&gt;&gt; model_results.pearson_residuals
    &gt;&gt;&gt; model_results.aic
    &gt;&gt;&gt; model_results.bic
    &gt;&gt;&gt; model_results.loglikelihood
    
    Notes
    -----
    MCGLM is a brand new model, which provides a solid statistical model for fitting multi-responses non-gaussian, dependent, or independent data based on second-moment assumptions. When a user instantiates an mcglm object, she must specify attributes such as link, variance, and z matrices; it will drive the overall behavior of the model.
    For more details, check articles and documentation provided.
    </code></pre>
</div>
</div>
<p>To instill <code>mcglm</code>, we begin with statistical analysis of i.i.d(independent and identically distributed) outcomes. For that, components <code>Z</code> will be specified as identity matrices, using method <code>mc_id()</code>. Upcoming examples epitomize the flexibility of <code>mcglm</code> in fitting different distribution models.</p>
<section id="diabetes-dataset" class="level5">
<h5 class="anchored" data-anchor-id="diabetes-dataset">1. Diabetes dataset</h5>
<p>Diabetes dataset outputs suited for regression modeling.</p>
<div class="cell" data-tags="[]" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_diabetes</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_diabetes(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> pd.DataFrame(X)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> pd.Series(y, name<span class="op">=</span><span class="st">"output"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># looking at target distribution</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.hist(y)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Histogram of California Dataset"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>Text(0.5, 1.0, 'Histogram of California Dataset')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="teste_files/figure-html/cell-4-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Starting with linear regression, fitting a linear regression through the <code>mcglm</code> library is plain. The picks are <code>identity</code> as a link, <code>constant</code> as variance, and an <code>identity matrix</code> as Z.</p>
<div class="cell" data-tags="[]" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>modelresults <span class="op">=</span> MCGLM(endog<span class="op">=</span>y, </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>                     exog<span class="op">=</span>X, </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                     z<span class="op">=</span>[mc_id(X)]</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                     ).fit()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>modelresults.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">

<table class="simpletable">
<caption>Multivariate Covariance Generalized Linear Model</caption>
<tbody><tr>
  <th>Dep. Variable:</th>      <td>output</td>      <th>  No. Iterations:    </th>      <td>1</td>    
</tr>
<tr>
  <th>Model:</th>               <td>MCGLM</td>      <th>  No. Observations:  </th>     <td>442</td>   
</tr>
<tr>
  <th>link:</th>              <td>identity</td>     <th>  Df Residuals:      </th>     <td>431</td>   
</tr>
<tr>
  <th>variance:</th>          <td>constant</td>     <th>  Df Model:          </th>     <td>11</td>    
</tr>
<tr>
  <th>Method:</th>        <td>Quasi-Likelihood</td> <th>  Power-fixed:       </th>    <td>True</td>   
</tr>
<tr>
  <th>Date:</th>          <td>Sun, 05 Feb 2023</td> <th>  pAIC               </th>   <td>5327.73</td> 
</tr>
<tr>
  <th>Time:</th>              <td>12:43:36</td>     <th>  pBIC               </th>   <td>5372.73</td> 
</tr>
<tr>
  <th> </th>                      <td> </td>        <th>  pLogLik            </th> <td>-2652.8628</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
  <td></td>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>0</th> <td>  -10.0099</td> <td>  177.919</td> <td>   -0.056</td> <td> 0.955</td> <td> -358.725</td> <td>  338.705</td>
</tr>
<tr>
  <th>1</th> <td> -239.8156</td> <td>  182.306</td> <td>   -1.315</td> <td> 0.188</td> <td> -597.128</td> <td>  117.497</td>
</tr>
<tr>
  <th>2</th> <td>  519.8459</td> <td>  198.121</td> <td>    2.624</td> <td> 0.009</td> <td>  131.536</td> <td>  908.156</td>
</tr>
<tr>
  <th>3</th> <td>  324.3846</td> <td>  194.811</td> <td>    1.665</td> <td> 0.096</td> <td>  -57.438</td> <td>  706.208</td>
</tr>
<tr>
  <th>4</th> <td> -792.1756</td> <td> 1240.774</td> <td>   -0.638</td> <td> 0.523</td> <td>-3224.047</td> <td> 1639.696</td>
</tr>
<tr>
  <th>5</th> <td>  476.7390</td> <td> 1009.552</td> <td>    0.472</td> <td> 0.637</td> <td>-1501.947</td> <td> 2455.425</td>
</tr>
<tr>
  <th>6</th> <td>  101.0433</td> <td>  632.868</td> <td>    0.160</td> <td> 0.873</td> <td>-1139.356</td> <td> 1341.442</td>
</tr>
<tr>
  <th>7</th> <td>  177.0632</td> <td>  480.837</td> <td>    0.368</td> <td> 0.713</td> <td> -765.359</td> <td> 1119.486</td>
</tr>
<tr>
  <th>8</th> <td>  751.2737</td> <td>  511.877</td> <td>    1.468</td> <td> 0.142</td> <td> -251.987</td> <td> 1754.535</td>
</tr>
<tr>
  <th>9</th> <td>   67.6267</td> <td>  196.486</td> <td>    0.344</td> <td> 0.731</td> <td> -317.478</td> <td>  452.731</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>dispersion_1</th> <td>   2.6e+04</td> <td>  796.484</td> <td>   32.649</td> <td> 0.000</td> <td> 2.44e+04</td> <td> 2.76e+04</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>power_</th> <td>    1.0000</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>
</tr>
</tbody></table>
</div>
</div>
<p>The residual analysis is key for assessing the fulfillment of the assumptions. For more details, check out (Montgomery. D.C and Runger. G.C, 2013).</p>
<div class="cell" data-tags="[]" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Residual Analysis</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(modelresults.mu, modelresults.pearson_residuals)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"mu"</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"pearson residuals"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>Text(0, 0.5, 'pearson residuals')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="teste_files/figure-html/cell-6-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>As long as the Pearson residuals aren’t shapeless, they may point to a non-optimal fitting.</p>
</section>
<section id="a-count-analysis" class="level5">
<h5 class="anchored" data-anchor-id="a-count-analysis">2. A count analysis</h5>
<p>This dataset hosts information from a Canadian study of mortality by age and smoking status. https://data.princeton.edu/wws509/datasets/#smoking. The four-column dataset establishes features: age, smoking status, population, and the outcome of deaths.</p>
<p>Linear regression is unsuitable for analyzing discrete count data, and a Poisson model is a usual choice. With <code>mcglm</code> is easy to leverage the Poisson Model.</p>
<div class="cell" data-tags="[]" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>smoking_data <span class="op">=</span> pd.read_csv(<span class="st">"data/smoking_data.csv"</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">## exog and endog</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> dmatrix(<span class="st">"~ pop + age + smoke"</span>, smoking_data, return_type<span class="op">=</span><span class="st">"dataframe"</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> smoking_data[<span class="st">"dead"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-tags="[]" data-execution_count="15">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.hist(y, bins<span class="op">=</span><span class="dv">40</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Histogram of absolute count of deads"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>Text(0.5, 1.0, 'Histogram of absolute count of deads')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="teste_files/figure-html/cell-8-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>That is a long-tail distribution.</p>
<p>Straight off the bat, we attempt fitting as a linear regression: <code>identity</code> and <code>constant</code>.</p>
<div class="cell" data-tags="[]" data-execution_count="16">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>modelresults <span class="op">=</span> MCGLM(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    y,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    X,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    [mc_id(X)],</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>).fit()</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>modelresults.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="16">

<table class="simpletable">
<caption>Multivariate Covariance Generalized Linear Model</caption>
<tbody><tr>
  <th>Dep. Variable:</th>       <td>dead</td>       <th>  No. Iterations:    </th>     <td>1</td>   
</tr>
<tr>
  <th>Model:</th>               <td>MCGLM</td>      <th>  No. Observations:  </th>    <td>36</td>   
</tr>
<tr>
  <th>link:</th>              <td>identity</td>     <th>  Df Residuals:      </th>    <td>22</td>   
</tr>
<tr>
  <th>variance:</th>          <td>constant</td>     <th>  Df Model:          </th>    <td>14</td>   
</tr>
<tr>
  <th>Method:</th>        <td>Quasi-Likelihood</td> <th>  Power-fixed:       </th>   <td>True</td>  
</tr>
<tr>
  <th>Date:</th>          <td>Sun, 05 Feb 2023</td> <th>  pAIC               </th>  <td>429.44</td> 
</tr>
<tr>
  <th>Time:</th>              <td>15:04:22</td>     <th>  pBIC               </th>  <td>451.61</td> 
</tr>
<tr>
  <th> </th>                      <td> </td>        <th>  pLogLik            </th> <td>-200.719</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
              <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                 <td> -224.6373</td> <td>   66.931</td> <td>   -3.356</td> <td> 0.001</td> <td> -355.820</td> <td>  -93.455</td>
</tr>
<tr>
  <th>age[T.45-59]</th>              <td>   95.3834</td> <td>   76.446</td> <td>    1.248</td> <td> 0.212</td> <td>  -54.448</td> <td>  245.215</td>
</tr>
<tr>
  <th>age[T.50-54]</th>              <td>  147.8634</td> <td>   78.491</td> <td>    1.884</td> <td> 0.060</td> <td>   -5.977</td> <td>  301.703</td>
</tr>
<tr>
  <th>age[T.55-59]</th>              <td>  216.4651</td> <td>   74.395</td> <td>    2.910</td> <td> 0.004</td> <td>   70.654</td> <td>  362.276</td>
</tr>
<tr>
  <th>age[T.60-64]</th>              <td>  344.0038</td> <td>   76.451</td> <td>    4.500</td> <td> 0.000</td> <td>  194.162</td> <td>  493.846</td>
</tr>
<tr>
  <th>age[T.65-69]</th>              <td>  426.7793</td> <td>   74.466</td> <td>    5.731</td> <td> 0.000</td> <td>  280.829</td> <td>  572.730</td>
</tr>
<tr>
  <th>age[T.70-74]</th>              <td>  399.1722</td> <td>   78.027</td> <td>    5.116</td> <td> 0.000</td> <td>  246.242</td> <td>  552.103</td>
</tr>
<tr>
  <th>age[T.75-79]</th>              <td>  335.9303</td> <td>   83.318</td> <td>    4.032</td> <td> 0.000</td> <td>  172.629</td> <td>  499.231</td>
</tr>
<tr>
  <th>age[T.80+]</th>                <td>  293.7420</td> <td>   86.312</td> <td>    3.403</td> <td> 0.001</td> <td>  124.573</td> <td>  462.911</td>
</tr>
<tr>
  <th>smoke[T.2.cigarPipeOnly]</th>  <td>   32.3389</td> <td>   49.616</td> <td>    0.652</td> <td> 0.515</td> <td>  -64.906</td> <td>  129.584</td>
</tr>
<tr>
  <th>smoke[T.3.cigarrettePlus]</th> <td>   85.2001</td> <td>   76.811</td> <td>    1.109</td> <td> 0.267</td> <td>  -65.347</td> <td>  235.747</td>
</tr>
<tr>
  <th>smoke[T.4.cigarretteOnly]</th> <td>   87.8965</td> <td>   60.879</td> <td>    1.444</td> <td> 0.149</td> <td>  -31.425</td> <td>  207.218</td>
</tr>
<tr>
  <th>pop</th>                       <td>    0.1128</td> <td>    0.023</td> <td>    4.814</td> <td> 0.000</td> <td>    0.067</td> <td>    0.159</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>dispersion_1</th> <td> 1.107e+04</td> <td> 1899.730</td> <td>    5.825</td> <td> 0.000</td> <td> 7342.638</td> <td> 1.48e+04</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>power_</th> <td>    1.0000</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>
</tr>
</tbody></table>
</div>
</div>
<p>Let’s try a <code>Tweedie</code> with a power set as one, as a <code>Poisson</code> model. As mentioned, Poisson is a suitable pick for modeling count data.</p>
<div class="cell" data-tags="[]" data-execution_count="17">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>modelresults <span class="op">=</span> MCGLM(</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    y,</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    X,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    [mc_id(X)],</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    link<span class="op">=</span><span class="st">"log"</span>,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    variance<span class="op">=</span><span class="st">"tweedie"</span>,</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    power<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    power_fixed<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>).fit()</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>modelresults.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="17">

<table class="simpletable">
<caption>Multivariate Covariance Generalized Linear Model</caption>
<tbody><tr>
  <th>Dep. Variable:</th>       <td>dead</td>       <th>  No. Iterations:    </th>     <td>1</td>    
</tr>
<tr>
  <th>Model:</th>               <td>MCGLM</td>      <th>  No. Observations:  </th>    <td>36</td>    
</tr>
<tr>
  <th>link:</th>                 <td>log</td>       <th>  Df Residuals:      </th>    <td>22</td>    
</tr>
<tr>
  <th>variance:</th>           <td>tweedie</td>     <th>  Df Model:          </th>    <td>14</td>    
</tr>
<tr>
  <th>Method:</th>        <td>Quasi-Likelihood</td> <th>  Power-fixed:       </th>   <td>True</td>   
</tr>
<tr>
  <th>Date:</th>          <td>Sun, 05 Feb 2023</td> <th>  pAIC               </th>  <td>371.22</td>  
</tr>
<tr>
  <th>Time:</th>              <td>15:04:51</td>     <th>  pBIC               </th>  <td>393.39</td>  
</tr>
<tr>
  <th> </th>                      <td> </td>        <th>  pLogLik            </th> <td>-171.6087</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
              <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                 <td>    2.5604</td> <td>    0.283</td> <td>    9.056</td> <td> 0.000</td> <td>    2.006</td> <td>    3.115</td>
</tr>
<tr>
  <th>age[T.45-59]</th>              <td>    0.6242</td> <td>    0.310</td> <td>    2.011</td> <td> 0.044</td> <td>    0.016</td> <td>    1.233</td>
</tr>
<tr>
  <th>age[T.50-54]</th>              <td>    1.0038</td> <td>    0.308</td> <td>    3.261</td> <td> 0.001</td> <td>    0.401</td> <td>    1.607</td>
</tr>
<tr>
  <th>age[T.55-59]</th>              <td>    1.3818</td> <td>    0.245</td> <td>    5.635</td> <td> 0.000</td> <td>    0.901</td> <td>    1.862</td>
</tr>
<tr>
  <th>age[T.60-64]</th>              <td>    1.5012</td> <td>    0.245</td> <td>    6.133</td> <td> 0.000</td> <td>    1.021</td> <td>    1.981</td>
</tr>
<tr>
  <th>age[T.65-69]</th>              <td>    2.1366</td> <td>    0.240</td> <td>    8.920</td> <td> 0.000</td> <td>    1.667</td> <td>    2.606</td>
</tr>
<tr>
  <th>age[T.70-74]</th>              <td>    2.3557</td> <td>    0.269</td> <td>    8.766</td> <td> 0.000</td> <td>    1.829</td> <td>    2.882</td>
</tr>
<tr>
  <th>age[T.75-79]</th>              <td>    2.2041</td> <td>    0.298</td> <td>    7.403</td> <td> 0.000</td> <td>    1.621</td> <td>    2.788</td>
</tr>
<tr>
  <th>age[T.80+]</th>                <td>    1.9506</td> <td>    0.318</td> <td>    6.143</td> <td> 0.000</td> <td>    1.328</td> <td>    2.573</td>
</tr>
<tr>
  <th>smoke[T.2.cigarPipeOnly]</th>  <td>    0.2114</td> <td>    0.176</td> <td>    1.203</td> <td> 0.229</td> <td>   -0.133</td> <td>    0.556</td>
</tr>
<tr>
  <th>smoke[T.3.cigarrettePlus]</th> <td>    0.5030</td> <td>    0.214</td> <td>    2.347</td> <td> 0.019</td> <td>    0.083</td> <td>    0.923</td>
</tr>
<tr>
  <th>smoke[T.4.cigarretteOnly]</th> <td>    0.7818</td> <td>    0.164</td> <td>    4.755</td> <td> 0.000</td> <td>    0.460</td> <td>    1.104</td>
</tr>
<tr>
  <th>pop</th>                       <td>    0.0004</td> <td> 6.25e-05</td> <td>    6.679</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>dispersion_1</th> <td>   14.1200</td> <td>    3.786</td> <td>    3.729</td> <td> 0.000</td> <td>    6.699</td> <td>   21.541</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>power_</th> <td>    1.0000</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>
</tr>
</tbody></table>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="18">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Residual Analysis</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(modelresults.mu, modelresults.pearson_residuals)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"mu"</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"pearson residuals"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>Text(0, 0.5, 'pearson residuals')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="teste_files/figure-html/cell-11-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>By the <code>pAIC</code> metric, the usual <code>Tweedie</code> variance function is a suitable pick.</p>
<hr>
<p>It is plain to harness an essential trait of the <code>mcglm</code> library, the power estimation for a <code>Poisson Tweedie</code> fitting. We have got to set the parameter power_fixed as <code>False</code>.</p>
<div class="cell" data-tags="[]" data-execution_count="19">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>modelresults <span class="op">=</span> MCGLM(</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    y,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    X,</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    [mc_id(X)],</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    link<span class="op">=</span><span class="st">"log"</span>,</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    variance<span class="op">=</span><span class="st">"poisson_tweedie"</span>,</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    power<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    power_fixed<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>).fit()</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>modelresults.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="19">

<table class="simpletable">
<caption>Multivariate Covariance Generalized Linear Model</caption>
<tbody><tr>
  <th>Dep. Variable:</th>       <td>dead</td>       <th>  No. Iterations:    </th>    <td>12</td>    
</tr>
<tr>
  <th>Model:</th>               <td>MCGLM</td>      <th>  No. Observations:  </th>    <td>36</td>    
</tr>
<tr>
  <th>link:</th>                 <td>log</td>       <th>  Df Residuals:      </th>    <td>22</td>    
</tr>
<tr>
  <th>variance:</th>       <td>poisson_tweedie</td> <th>  Df Model:          </th>    <td>14</td>    
</tr>
<tr>
  <th>Method:</th>        <td>Quasi-Likelihood</td> <th>  Power-fixed:       </th>   <td>False</td>  
</tr>
<tr>
  <th>Date:</th>          <td>Sun, 05 Feb 2023</td> <th>  pAIC               </th>  <td>370.17</td>  
</tr>
<tr>
  <th>Time:</th>              <td>15:05:20</td>     <th>  pBIC               </th>  <td>392.34</td>  
</tr>
<tr>
  <th> </th>                      <td> </td>        <th>  pLogLik            </th> <td>-171.0843</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
              <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                 <td>    2.4466</td> <td>    0.269</td> <td>    9.094</td> <td> 0.000</td> <td>    1.919</td> <td>    2.974</td>
</tr>
<tr>
  <th>age[T.45-59]</th>              <td>    0.6573</td> <td>    0.297</td> <td>    2.209</td> <td> 0.027</td> <td>    0.074</td> <td>    1.240</td>
</tr>
<tr>
  <th>age[T.50-54]</th>              <td>    1.0419</td> <td>    0.298</td> <td>    3.498</td> <td> 0.000</td> <td>    0.458</td> <td>    1.626</td>
</tr>
<tr>
  <th>age[T.55-59]</th>              <td>    1.3900</td> <td>    0.244</td> <td>    5.703</td> <td> 0.000</td> <td>    0.912</td> <td>    1.868</td>
</tr>
<tr>
  <th>age[T.60-64]</th>              <td>    1.5253</td> <td>    0.242</td> <td>    6.300</td> <td> 0.000</td> <td>    1.051</td> <td>    2.000</td>
</tr>
<tr>
  <th>age[T.65-69]</th>              <td>    2.1935</td> <td>    0.236</td> <td>    9.283</td> <td> 0.000</td> <td>    1.730</td> <td>    2.657</td>
</tr>
<tr>
  <th>age[T.70-74]</th>              <td>    2.4571</td> <td>    0.263</td> <td>    9.350</td> <td> 0.000</td> <td>    1.942</td> <td>    2.972</td>
</tr>
<tr>
  <th>age[T.75-79]</th>              <td>    2.3416</td> <td>    0.290</td> <td>    8.082</td> <td> 0.000</td> <td>    1.774</td> <td>    2.909</td>
</tr>
<tr>
  <th>age[T.80+]</th>                <td>    2.1177</td> <td>    0.307</td> <td>    6.906</td> <td> 0.000</td> <td>    1.517</td> <td>    2.719</td>
</tr>
<tr>
  <th>smoke[T.2.cigarPipeOnly]</th>  <td>    0.1685</td> <td>    0.172</td> <td>    0.980</td> <td> 0.327</td> <td>   -0.168</td> <td>    0.505</td>
</tr>
<tr>
  <th>smoke[T.3.cigarrettePlus]</th> <td>    0.4427</td> <td>    0.217</td> <td>    2.041</td> <td> 0.041</td> <td>    0.017</td> <td>    0.868</td>
</tr>
<tr>
  <th>smoke[T.4.cigarretteOnly]</th> <td>    0.7345</td> <td>    0.167</td> <td>    4.398</td> <td> 0.000</td> <td>    0.407</td> <td>    1.062</td>
</tr>
<tr>
  <th>pop</th>                       <td>    0.0005</td> <td>  6.4e-05</td> <td>    7.110</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>dispersion_1</th> <td>    3.0590</td> <td>    3.121</td> <td>    0.980</td> <td> 0.327</td> <td>   -3.059</td> <td>    9.177</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>power_</th> <td>    1.2895</td> <td>    0.198</td> <td>    6.526</td> <td> 0.000</td> <td>    0.902</td> <td>    1.677</td>
</tr>
</tbody></table>
</div>
</div>
<p>By the <code>pAIC</code>, the adjustment with <code>Poisson Tweedie</code> power set 1.263 is lightly better than <code>Poisson</code> 1. It points out that the distribution <code>Poisson Tweedie</code> is the best option for this data learning.</p>
</section>
<section id="a-bounded-analysis" class="level5">
<h5 class="anchored" data-anchor-id="a-bounded-analysis">3. A bounded analysis</h5>
<p>For a bound analysis, we analyze the iconic titanic dataset.</p>
<div class="cell" data-tags="[]" data-execution_count="21">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>titanic <span class="op">=</span> pd.read_csv(<span class="st">"data/titanic.csv"</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> titanic[<span class="st">"Survived"</span>]</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> titanic[[<span class="st">"Fare"</span>, <span class="st">"SibSp"</span>, <span class="st">"Embarked"</span>, <span class="st">"Parch"</span>, <span class="st">"Pclass"</span>]]</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X.fillna(<span class="st">"S"</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> dmatrix(<span class="st">"~ Fare + SibSp + Embarked + Parch + Pclass"</span>, X, return_type<span class="op">=</span><span class="st">"dataframe"</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>modelresults <span class="op">=</span> MCGLM(</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    y,</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    X,</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    [mc_id(X)],</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    link<span class="op">=</span><span class="st">"logit"</span>,</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    variance<span class="op">=</span><span class="st">"binomialP"</span>,</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    ntrial<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>).fit()</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>modelresults.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="21">

<table class="simpletable">
<caption>Multivariate Covariance Generalized Linear Model</caption>
<tbody><tr>
  <th>Dep. Variable:</th>     <td>Survived</td>     <th>  No. Iterations:    </th>     <td>1</td>   
</tr>
<tr>
  <th>Model:</th>               <td>MCGLM</td>      <th>  No. Observations:  </th>    <td>891</td>  
</tr>
<tr>
  <th>link:</th>                <td>logit</td>      <th>  Df Residuals:      </th>    <td>883</td>  
</tr>
<tr>
  <th>variance:</th>          <td>binomialP</td>    <th>  Df Model:          </th>     <td>8</td>   
</tr>
<tr>
  <th>Method:</th>        <td>Quasi-Likelihood</td> <th>  Power-fixed:       </th>   <td>True</td>  
</tr>
<tr>
  <th>Date:</th>          <td>Sun, 05 Feb 2023</td> <th>  pAIC               </th>  <td>212.54</td> 
</tr>
<tr>
  <th>Time:</th>              <td>15:06:04</td>     <th>  pBIC               </th>  <td>250.88</td> 
</tr>
<tr>
  <th> </th>                      <td> </td>        <th>  pLogLik            </th> <td>-98.2698</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>     <td>    1.4120</td> <td>    0.343</td> <td>    4.122</td> <td> 0.000</td> <td>    0.741</td> <td>    2.083</td>
</tr>
<tr>
  <th>Embarked[T.Q]</th> <td>    0.2911</td> <td>    0.307</td> <td>    0.949</td> <td> 0.343</td> <td>   -0.310</td> <td>    0.893</td>
</tr>
<tr>
  <th>Embarked[T.S]</th> <td>   -0.5179</td> <td>    0.196</td> <td>   -2.636</td> <td> 0.008</td> <td>   -0.903</td> <td>   -0.133</td>
</tr>
<tr>
  <th>Fare</th>          <td>    0.0037</td> <td>    0.002</td> <td>    1.554</td> <td> 0.120</td> <td>   -0.001</td> <td>    0.008</td>
</tr>
<tr>
  <th>SibSp</th>         <td>   -0.1274</td> <td>    0.082</td> <td>   -1.561</td> <td> 0.119</td> <td>   -0.287</td> <td>    0.033</td>
</tr>
<tr>
  <th>Parch</th>         <td>    0.2920</td> <td>    0.101</td> <td>    2.906</td> <td> 0.004</td> <td>    0.095</td> <td>    0.489</td>
</tr>
<tr>
  <th>Pclass</th>        <td>   -0.7556</td> <td>    0.116</td> <td>   -6.508</td> <td> 0.000</td> <td>   -0.983</td> <td>   -0.528</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>dispersion_1</th> <td>    0.9990</td> <td>    0.036</td> <td>   27.961</td> <td> 0.000</td> <td>    0.929</td> <td>    1.069</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>power_</th> <td>    1.0000</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>
</tr>
</tbody></table>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="22">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Evaluating multiple links</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>modelresults_logit <span class="op">=</span> MCGLM(</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    y, X, [mc_id(X)], link<span class="op">=</span><span class="st">"logit"</span>, variance<span class="op">=</span><span class="st">"binomialP"</span>, ntrial<span class="op">=</span><span class="dv">1</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>).fit()</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>modelresults_loglog <span class="op">=</span> MCGLM(</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    y, X, [mc_id(X)], link<span class="op">=</span><span class="st">"loglog"</span>, variance<span class="op">=</span><span class="st">"binomialP"</span>, ntrial<span class="op">=</span><span class="dv">1</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>).fit()</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>modelresults_cloglog <span class="op">=</span> MCGLM(</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    y, X, [mc_id(X)], link<span class="op">=</span><span class="st">"cloglog"</span>, variance<span class="op">=</span><span class="st">"binomialP"</span>, ntrial<span class="op">=</span><span class="dv">1</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>).fit()</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>modelresults_cauchy <span class="op">=</span> MCGLM(</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    y, X, [mc_id(X)], link<span class="op">=</span><span class="st">"cauchy"</span>, variance<span class="op">=</span><span class="st">"binomialP"</span>, ntrial<span class="op">=</span><span class="dv">1</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>).fit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-tags="[]" data-execution_count="23">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"logit_aic: "</span>,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    modelresults_logit.aic,</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">", loglog_aic: "</span>,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    modelresults_loglog.aic,</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">", cloglog_aic: "</span>,</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    modelresults_cloglog.aic,</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">", cauchy_aic: "</span>,</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    modelresults_cauchy.aic,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>logit_aic:  212.54 , loglog_aic:  202.04 , cloglog_aic:  222.58 , cauchy_aic:  216.94</code></pre>
</div>
</div>
<p>The loglog link is the best pick for this analysis.</p>
<p>In addition, the <code>mcglm</code> can fit response variables when its realizations are non-independent.</p>
</section>
</section>
<section id="non-independent-section" class="level3">
<h3 class="anchored" data-anchor-id="non-independent-section">Non-independent section</h3>
<p>Let’s leverage the <code>mcglm</code> to adjust non-independent data, illustrated by a Moving Average and Mixed Model analysis, two iconic statistical models.</p>
<section id="moving-average-model" class="level5">
<h5 class="anchored" data-anchor-id="moving-average-model">1. Moving Average model</h5>
<p>In MA model, the current realization is linearly dependent of past error terms. The script below defines a MA realization of size 1, and <code>q</code> defined as <code>0.4</code>.</p>
<div class="cell" data-tags="[]" data-execution_count="37">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>SAMPLE_SIZE <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>RANDOM_SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.zeros((SAMPLE_SIZE,))</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co"># true stationarity</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>true_theta <span class="op">=</span> <span class="fl">0.4</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co"># true standard deviation of the innovation:</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>true_sigma <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co"># true process mean:</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>true_center <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>innovations <span class="op">=</span> np.random.normal(true_center, true_sigma, SAMPLE_SIZE)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, SAMPLE_SIZE):</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    y[t] <span class="op">=</span> innovations[t] <span class="op">+</span> true_theta <span class="op">*</span> innovations[t<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>plt.plot(y, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Timestep"</span>)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"$y$"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>Text(0, 0.5, '$y$')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="teste_files/figure-html/cell-16-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="38">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># building covariance matrix and outcome vector.</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame()</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>data[<span class="st">"ma_sample"</span>] <span class="op">=</span> y</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>data[<span class="st">"index"</span>] <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">0</span>, SAMPLE_SIZE))</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> add_constant(data)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data[[<span class="st">"const"</span>]]</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">"ma_sample"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>To find the best size for MA, the <code>q</code> fitting, we benchmark them by <code>pAIC</code>. Moreover, the <code>mc_ma</code> assist us in building the Z matrices for the MA analysis.</p>
<div class="cell" data-tags="[]" data-execution_count="39">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>one_order <span class="op">=</span> [mc_id(X), mc_ma(<span class="bu">id</span><span class="op">=</span><span class="st">"const"</span>, time<span class="op">=</span><span class="st">"index"</span>, data<span class="op">=</span>data, order<span class="op">=</span><span class="dv">1</span>)]</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>two_order <span class="op">=</span> [<span class="op">*</span>one_order, mc_ma(<span class="bu">id</span><span class="op">=</span><span class="st">"const"</span>, time<span class="op">=</span><span class="st">"index"</span>, data<span class="op">=</span>data, order<span class="op">=</span><span class="dv">2</span>)]</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>three_order <span class="op">=</span> [<span class="op">*</span>two_order, mc_ma(<span class="bu">id</span><span class="op">=</span><span class="st">"const"</span>, time<span class="op">=</span><span class="st">"index"</span>, data<span class="op">=</span>data, order<span class="op">=</span><span class="dv">3</span>)]</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>four_order <span class="op">=</span> [<span class="op">*</span>three_order, mc_ma(<span class="bu">id</span><span class="op">=</span><span class="st">"const"</span>, time<span class="op">=</span><span class="st">"index"</span>, data<span class="op">=</span>data, order<span class="op">=</span><span class="dv">4</span>)]</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>five_order <span class="op">=</span> [<span class="op">*</span>four_order, mc_ma(<span class="bu">id</span><span class="op">=</span><span class="st">"const"</span>, time<span class="op">=</span><span class="st">"index"</span>, data<span class="op">=</span>data, order<span class="op">=</span><span class="dv">5</span>)]</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>six_order <span class="op">=</span> [<span class="op">*</span>five_order, mc_ma(<span class="bu">id</span><span class="op">=</span><span class="st">"const"</span>, time<span class="op">=</span><span class="st">"index"</span>, data<span class="op">=</span>data, order<span class="op">=</span><span class="dv">6</span>)]</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>seven_order <span class="op">=</span> [<span class="op">*</span>six_order, mc_ma(<span class="bu">id</span><span class="op">=</span><span class="st">"const"</span>, time<span class="op">=</span><span class="st">"index"</span>, data<span class="op">=</span>data, order<span class="op">=</span><span class="dv">7</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-tags="[]" data-execution_count="40">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index, order <span class="kw">in</span> <span class="bu">enumerate</span>(</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    [one_order, two_order, three_order, four_order, five_order, six_order, seven_order]</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    modelresults <span class="op">=</span> MCGLM(y, X, order).fit()</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"q value: "</span>, <span class="bu">str</span>(index <span class="op">+</span> <span class="dv">1</span>), <span class="st">", paic: "</span>, modelresults.aic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>q value:  1 , paic:  900.42
q value:  2 , paic:  902.27
q value:  3 , paic:  901.7
q value:  4 , paic:  903.63
q value:  5 , paic:  905.19
q value:  6 , paic:  906.69
q value:  7 , paic:  907.43</code></pre>
</div>
</div>
<p>Displacement q as 1 as the best fit.</p>
<div class="cell" data-tags="[]" data-execution_count="41">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>modelresults <span class="op">=</span> MCGLM(y, X, one_order).fit()</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>modelresults.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="41">

<table class="simpletable">
<caption>Multivariate Covariance Generalized Linear Model</caption>
<tbody><tr>
  <th>Dep. Variable:</th>     <td>ma_sample</td>    <th>  No. Iterations:    </th>     <td>2</td>    
</tr>
<tr>
  <th>Model:</th>               <td>MCGLM</td>      <th>  No. Observations:  </th>    <td>500</td>   
</tr>
<tr>
  <th>link:</th>              <td>identity</td>     <th>  Df Residuals:      </th>    <td>497</td>   
</tr>
<tr>
  <th>variance:</th>          <td>constant</td>     <th>  Df Model:          </th>     <td>3</td>    
</tr>
<tr>
  <th>Method:</th>        <td>Quasi-Likelihood</td> <th>  Power-fixed:       </th>   <td>True</td>   
</tr>
<tr>
  <th>Date:</th>          <td>Sun, 05 Feb 2023</td> <th>  pAIC               </th>  <td>900.42</td>  
</tr>
<tr>
  <th>Time:</th>              <td>15:13:57</td>     <th>  pBIC               </th>  <td>913.07</td>  
</tr>
<tr>
  <th> </th>                      <td> </td>        <th>  pLogLik            </th> <td>-447.2117</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th> <td>   -0.0653</td> <td>    0.063</td> <td>   -1.036</td> <td> 0.300</td> <td>   -0.189</td> <td>    0.058</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>dispersion_1</th> <td>    1.1390</td> <td>    0.083</td> <td>   13.800</td> <td> 0.000</td> <td>    0.977</td> <td>    1.301</td>
</tr>
<tr>
  <th>dispersion_2</th> <td>    0.4230</td> <td>    0.047</td> <td>    9.091</td> <td> 0.000</td> <td>    0.332</td> <td>    0.514</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>power_</th> <td>    1.0000</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>
</tr>
</tbody></table>
</div>
</div>
<p>The summary report drills down the <span class="math inline">\(\theta\)</span> parameters that linearly operate the Gaussian White Noise, and 0.4, the actual value, falls within the interval of the second dispersion parameter.</p>
</section>
<section id="random-effect-models" class="level5">
<h5 class="anchored" data-anchor-id="random-effect-models">2. Random Effect models</h5>
<p>The dataset <code>sleepstudy</code> is a study of sleep deprivation. https://www.rdocumentation.org/packages/lme4/versions/1.1-26/topics/sleepstudy.</p>
<p>The study aims to understand the influence of sleep deprivation on reaction time. On day 0, subjects had their usual amount of sleep. From day 0 on, they were restricted to 3 hours of sleep per night. The observations represent the average reaction time on a series of tests given each day to each subject.</p>
<p>One promising approach is fitting through two-level effect models, such as <code>mixed models</code>. The <code>mcglm</code> library is a perfect framework to apply this statistical learning; due to the model and the method <code>mc_mixed()</code> to build a dependence matrix.</p>
<div class="cell" data-tags="[]" data-execution_count="42">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Top 10 cells to get an intuition about data.</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>sleepstudy <span class="op">=</span> pd.read_csv(</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"data/first_simulation/sleepstudy.csv"</span>, dtype<span class="op">=</span>{<span class="st">"Subject"</span>: <span class="st">"str"</span>}</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>sleepstudy.head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="42">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Reaction</th>
      <th>Days</th>
      <th>Subject</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>249.5600</td>
      <td>0</td>
      <td>308</td>
    </tr>
    <tr>
      <th>1</th>
      <td>258.7047</td>
      <td>1</td>
      <td>308</td>
    </tr>
    <tr>
      <th>2</th>
      <td>250.8006</td>
      <td>2</td>
      <td>308</td>
    </tr>
    <tr>
      <th>3</th>
      <td>321.4398</td>
      <td>3</td>
      <td>308</td>
    </tr>
    <tr>
      <th>4</th>
      <td>356.8519</td>
      <td>4</td>
      <td>308</td>
    </tr>
    <tr>
      <th>5</th>
      <td>414.6901</td>
      <td>5</td>
      <td>308</td>
    </tr>
    <tr>
      <th>6</th>
      <td>382.2038</td>
      <td>6</td>
      <td>308</td>
    </tr>
    <tr>
      <th>7</th>
      <td>290.1486</td>
      <td>7</td>
      <td>308</td>
    </tr>
    <tr>
      <th>8</th>
      <td>430.5853</td>
      <td>8</td>
      <td>308</td>
    </tr>
    <tr>
      <th>9</th>
      <td>466.3535</td>
      <td>9</td>
      <td>308</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="43">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Plotting curve of 18 subjects</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> sns.lineplot(x<span class="op">=</span><span class="st">"Days"</span>, y<span class="op">=</span><span class="st">"Reaction"</span>, hue<span class="op">=</span><span class="st">"Subject"</span>, data<span class="op">=</span>sleepstudy)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>plt.legend(bbox_to_anchor<span class="op">=</span>(<span class="fl">1.05</span>, <span class="dv">1</span>), loc<span class="op">=</span><span class="dv">2</span>, borderaxespad<span class="op">=</span><span class="fl">0.0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>&lt;matplotlib.legend.Legend at 0x7faedbd5b1f0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="teste_files/figure-html/cell-22-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-tags="[]" data-execution_count="44">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Design Matrix</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> dmatrix(<span class="st">"~ Days"</span>, sleepstudy, return_type<span class="op">=</span><span class="st">"dataframe"</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Z specification</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> [mc_id(sleepstudy)] <span class="op">+</span> mc_mixed(formula<span class="op">=</span><span class="st">"~ 0 + Subject / Days"</span>, data<span class="op">=</span>sleepstudy)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Model fitting</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>mcglm <span class="op">=</span> MCGLM(endog<span class="op">=</span>sleepstudy[<span class="st">"Reaction"</span>], exog<span class="op">=</span>X, z<span class="op">=</span>Z)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>mcglmresults <span class="op">=</span> mcglm.fit()</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>mcglmresults.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="44">

<table class="simpletable">
<caption>Multivariate Covariance Generalized Linear Model</caption>
<tbody><tr>
  <th>Dep. Variable:</th>     <td>Reaction</td>     <th>  No. Iterations:    </th>     <td>1</td>    
</tr>
<tr>
  <th>Model:</th>               <td>MCGLM</td>      <th>  No. Observations:  </th>    <td>180</td>   
</tr>
<tr>
  <th>link:</th>              <td>identity</td>     <th>  Df Residuals:      </th>    <td>174</td>   
</tr>
<tr>
  <th>variance:</th>          <td>constant</td>     <th>  Df Model:          </th>     <td>6</td>    
</tr>
<tr>
  <th>Method:</th>        <td>Quasi-Likelihood</td> <th>  Power-fixed:       </th>   <td>True</td>   
</tr>
<tr>
  <th>Date:</th>          <td>Sun, 05 Feb 2023</td> <th>  pAIC               </th>  <td>1583.94</td> 
</tr>
<tr>
  <th>Time:</th>              <td>15:15:45</td>     <th>  pBIC               </th>  <td>1603.1</td>  
</tr>
<tr>
  <th> </th>                      <td> </td>        <th>  pLogLik            </th> <td>-785.9702</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>  251.4051</td> <td>    6.632</td> <td>   37.906</td> <td> 0.000</td> <td>  238.406</td> <td>  264.404</td>
</tr>
<tr>
  <th>Days</th>      <td>   10.4673</td> <td>    1.502</td> <td>    6.968</td> <td> 0.000</td> <td>    7.523</td> <td>   13.412</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>dispersion_1</th> <td>  654.9410</td> <td>   70.624</td> <td>    9.274</td> <td> 0.000</td> <td>  516.521</td> <td>  793.361</td>
</tr>
<tr>
  <th>dispersion_2</th> <td>  565.5150</td> <td>  264.679</td> <td>    2.137</td> <td> 0.033</td> <td>   46.753</td> <td> 1084.277</td>
</tr>
<tr>
  <th>dispersion_3</th> <td>   32.6820</td> <td>   13.560</td> <td>    2.410</td> <td> 0.016</td> <td>    6.105</td> <td>   59.259</td>
</tr>
<tr>
  <th>dispersion_4</th> <td>   11.0550</td> <td>   42.948</td> <td>    0.257</td> <td> 0.797</td> <td>  -73.121</td> <td>   95.231</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>power_</th> <td>    1.0000</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>
</tr>
</tbody></table>
</div>
</div>
<ul>
<li><p>Regression coefficients<br>
The regression section diagnose the fixed-effects parameters, that is to say, the conclusion overall subjects.</p>
<p>Intercept set at value 251.40. The straightforward takeaway is: At day 0, the average response time is roughly 251 seconds. In addition, Days at 10.46 allude to total change to response time by unit changes on Days, for subjects with random effects set to 0. Furthermore, by the results of the wald test on Days, we might conclude that days are statistically significant for the model.</p></li>
<li><p>Dispersion parameters<br>
The dispersion parameters allude to random effects within individuals throughout the days.</p>
<p>The first dispersion parameter is the variance across all data points. Calculated in 654.94. The second dispersion parameter is the variance across all intercepts, which is 565.51. The third dispersion parameter is the variance across all slopes. Calculated in 32.68. The fourth dispersion parameter is the variance across intercepts and slopes. Calculated in 11.05.</p></li>
<li><p>Moreover, the correlation might be calculated through the formula = dispersion_4/sqrt(dispersion_2 * dispersion_3). Cell below shows the pearson correlation result, 0.0812.</p></li>
</ul>
<p>Furthermore, <code>mcglm</code> can also do multivariate analysis.</p>
</section>
<section id="multivariate-models" class="level4">
<h4 class="anchored" data-anchor-id="multivariate-models">Multivariate Models</h4>
<p>Soya</p>
<p><code>Soya</code> is a dataset that stores an experiment of Universidade Federal da Grande Dourados in Dourados, Mato Grosso do Sul, Brazil. Description:<br>
https://github.com/walmes/wzRfun/blob/master/R/wzRfun.R#L10<br>
http://ccarevista.ufc.br/seer/index.php/ccarevista/article/view/1454</p>
<p>The experiment collected data about different treatments of <code>potassium</code>, <code>water</code>, and <code>blocks</code> for soil farming on buckets. All of those covariates are categorical. The response traits to be analyzed are: <code>grain size</code>, <code>total seeds</code>, and <code>viable peas</code>, which stands for the weight of hundred grains, total grain per bucket, and percentage of viable peas(green beans). In the following, MCGLM fits onto this data with three unique answers: continuous, count, and binomial.</p>
<div class="cell" data-tags="[]" data-execution_count="45">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>soya <span class="op">=</span> pd.read_csv(</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"data/fourth_simulation/soya.csv"</span>,</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    dtype<span class="op">=</span>{<span class="st">"block"</span>: <span class="st">"str"</span>, <span class="st">"water"</span>: <span class="st">"str"</span>, <span class="st">"pot"</span>: <span class="st">"str"</span>},</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># percentual of peas.</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>soya[<span class="st">"viablePeas"</span>] <span class="op">=</span> soya[<span class="st">"viablepeas"</span>] <span class="op">/</span> soya[<span class="st">"totalpeas"</span>]</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Design matrix.</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> dmatrix(<span class="st">"~ block + water * pot"</span>, soya, return_type<span class="op">=</span><span class="st">"dataframe"</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Specification</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>mcglm <span class="op">=</span> MCGLM(</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    endog<span class="op">=</span>[soya[<span class="st">"grain"</span>], soya[<span class="st">"seeds"</span>], soya[<span class="st">"viablePeas"</span>]],</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    exog<span class="op">=</span>[X, X, X],</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>    z<span class="op">=</span>[[mc_id(soya)], [mc_id(soya)], [mc_id(soya)]],</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    link<span class="op">=</span>[<span class="st">"identity"</span>, <span class="st">"log"</span>, <span class="st">"logit"</span>],</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    variance<span class="op">=</span>[<span class="st">"constant"</span>, <span class="st">"tweedie"</span>, <span class="st">"binomialP"</span>],</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    ntrial<span class="op">=</span>[<span class="va">None</span>, <span class="va">None</span>, soya[<span class="st">"totalpeas"</span>].values],</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>mcglmresults <span class="op">=</span> mcglm.fit()</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>mcglmresults.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="45">

<table class="simpletable">
<caption>Multivariate Covariance Generalized Linear Model</caption>
<tbody><tr>
  <th>Dep. Variable:</th>       <td>grain</td>      <th>  No. Iterations:    </th>     <td>3</td>    
</tr>
<tr>
  <th>Model:</th>               <td>MCGLM</td>      <th>  No. Observations:  </th>    <td>75</td>    
</tr>
<tr>
  <th>link:</th>              <td>identity</td>     <th>  Df Residuals:      </th>    <td>55</td>    
</tr>
<tr>
  <th>variance:</th>          <td>constant</td>     <th>  Df Model:          </th>    <td>20</td>    
</tr>
<tr>
  <th>Method:</th>        <td>Quasi-Likelihood</td> <th>  Power-fixed:       </th>   <td>True</td>   
</tr>
<tr>
  <th>Date:</th>          <td>Sun, 05 Feb 2023</td> <th>  pAIC               </th>  <td>448.02</td>  
</tr>
<tr>
  <th>Time:</th>              <td>15:16:55</td>     <th>  pBIC               </th>  <td>516.34</td>  
</tr>
<tr>
  <th> </th>                      <td> </td>        <th>  pLogLik            </th> <td>-204.0085</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                <td>   14.2455</td> <td>    1.217</td> <td>   11.701</td> <td> 0.000</td> <td>   11.859</td> <td>   16.632</td>
</tr>
<tr>
  <th>block[T.II]</th>              <td>    1.1326</td> <td>    0.880</td> <td>    1.287</td> <td> 0.198</td> <td>   -0.593</td> <td>    2.858</td>
</tr>
<tr>
  <th>block[T.III]</th>             <td>   -0.7797</td> <td>    0.880</td> <td>   -0.886</td> <td> 0.376</td> <td>   -2.505</td> <td>    0.946</td>
</tr>
<tr>
  <th>block[T.IV]</th>              <td>   -1.5495</td> <td>    0.880</td> <td>   -1.760</td> <td> 0.078</td> <td>   -3.275</td> <td>    0.176</td>
</tr>
<tr>
  <th>block[T.V]</th>               <td>   -2.3866</td> <td>    0.880</td> <td>   -2.711</td> <td> 0.007</td> <td>   -4.112</td> <td>   -0.661</td>
</tr>
<tr>
  <th>water[T.50]</th>              <td>    2.1660</td> <td>    1.531</td> <td>    1.415</td> <td> 0.157</td> <td>   -0.834</td> <td>    5.166</td>
</tr>
<tr>
  <th>water[T.62.5]</th>            <td>    2.5404</td> <td>    1.531</td> <td>    1.660</td> <td> 0.097</td> <td>   -0.460</td> <td>    5.541</td>
</tr>
<tr>
  <th>pot[T.120]</th>               <td>   11.7898</td> <td>    1.531</td> <td>    7.702</td> <td> 0.000</td> <td>    8.790</td> <td>   14.790</td>
</tr>
<tr>
  <th>pot[T.180]</th>               <td>   11.8633</td> <td>    1.531</td> <td>    7.750</td> <td> 0.000</td> <td>    8.863</td> <td>   14.864</td>
</tr>
<tr>
  <th>pot[T.30]</th>                <td>    6.7894</td> <td>    1.531</td> <td>    4.435</td> <td> 0.000</td> <td>    3.789</td> <td>    9.790</td>
</tr>
<tr>
  <th>pot[T.60]</th>                <td>   10.3978</td> <td>    1.531</td> <td>    6.793</td> <td> 0.000</td> <td>    7.398</td> <td>   13.398</td>
</tr>
<tr>
  <th>water[T.50]:pot[T.120]</th>   <td>    2.2541</td> <td>    2.165</td> <td>    1.041</td> <td> 0.298</td> <td>   -1.989</td> <td>    6.497</td>
</tr>
<tr>
  <th>water[T.62.5]:pot[T.120]</th> <td>    5.5826</td> <td>    2.165</td> <td>    2.579</td> <td> 0.010</td> <td>    1.340</td> <td>    9.826</td>
</tr>
<tr>
  <th>water[T.50]:pot[T.180]</th>   <td>    1.2097</td> <td>    2.165</td> <td>    0.559</td> <td> 0.576</td> <td>   -3.033</td> <td>    5.453</td>
</tr>
<tr>
  <th>water[T.62.5]:pot[T.180]</th> <td>    9.2391</td> <td>    2.165</td> <td>    4.268</td> <td> 0.000</td> <td>    4.996</td> <td>   13.482</td>
</tr>
<tr>
  <th>water[T.50]:pot[T.30]</th>    <td>    0.1069</td> <td>    2.165</td> <td>    0.049</td> <td> 0.961</td> <td>   -4.136</td> <td>    4.350</td>
</tr>
<tr>
  <th>water[T.62.5]:pot[T.30]</th>  <td>   -1.8677</td> <td>    2.165</td> <td>   -0.863</td> <td> 0.388</td> <td>   -6.111</td> <td>    2.375</td>
</tr>
<tr>
  <th>water[T.50]:pot[T.60]</th>    <td>    2.6035</td> <td>    2.165</td> <td>    1.203</td> <td> 0.229</td> <td>   -1.640</td> <td>    6.847</td>
</tr>
<tr>
  <th>water[T.62.5]:pot[T.60]</th>  <td>    3.3585</td> <td>    2.165</td> <td>    1.551</td> <td> 0.121</td> <td>   -0.885</td> <td>    7.602</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>dispersion_1</th> <td>    5.8610</td> <td>    1.671</td> <td>    3.507</td> <td> 0.000</td> <td>    2.586</td> <td>    9.136</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>power_</th> <td>    1.0000</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>
</tr>
</tbody></table>
<table class="simpletable">
<caption>Multivariate Covariance Generalized Linear Model</caption>
<tbody><tr>
  <th>Dep. Variable:</th>       <td>seeds</td>      <th>  No. Iterations:    </th>     <td>3</td>    
</tr>
<tr>
  <th>Model:</th>               <td>MCGLM</td>      <th>  No. Observations:  </th>    <td>75</td>    
</tr>
<tr>
  <th>link:</th>                 <td>log</td>       <th>  Df Residuals:      </th>    <td>55</td>    
</tr>
<tr>
  <th>variance:</th>           <td>tweedie</td>     <th>  Df Model:          </th>    <td>20</td>    
</tr>
<tr>
  <th>Method:</th>        <td>Quasi-Likelihood</td> <th>  Power-fixed:       </th>   <td>True</td>   
</tr>
<tr>
  <th>Date:</th>          <td>Sun, 05 Feb 2023</td> <th>  pAIC               </th>  <td>448.02</td>  
</tr>
<tr>
  <th>Time:</th>              <td>15:16:55</td>     <th>  pBIC               </th>  <td>516.34</td>  
</tr>
<tr>
  <th> </th>                      <td> </td>        <th>  pLogLik            </th> <td>-204.0085</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                <td>    4.8074</td> <td>    0.066</td> <td>   73.109</td> <td> 0.000</td> <td>    4.679</td> <td>    4.936</td>
</tr>
<tr>
  <th>block[T.II]</th>              <td>   -0.0182</td> <td>    0.039</td> <td>   -0.469</td> <td> 0.639</td> <td>   -0.094</td> <td>    0.058</td>
</tr>
<tr>
  <th>block[T.III]</th>             <td>   -0.0330</td> <td>    0.039</td> <td>   -0.845</td> <td> 0.398</td> <td>   -0.110</td> <td>    0.044</td>
</tr>
<tr>
  <th>block[T.IV]</th>              <td>   -0.1066</td> <td>    0.040</td> <td>   -2.679</td> <td> 0.007</td> <td>   -0.185</td> <td>   -0.029</td>
</tr>
<tr>
  <th>block[T.V]</th>               <td>   -0.1261</td> <td>    0.040</td> <td>   -3.154</td> <td> 0.002</td> <td>   -0.205</td> <td>   -0.048</td>
</tr>
<tr>
  <th>water[T.50]</th>              <td>    0.1322</td> <td>    0.084</td> <td>    1.580</td> <td> 0.114</td> <td>   -0.032</td> <td>    0.296</td>
</tr>
<tr>
  <th>water[T.62.5]</th>            <td>    0.1864</td> <td>    0.083</td> <td>    2.255</td> <td> 0.024</td> <td>    0.024</td> <td>    0.348</td>
</tr>
<tr>
  <th>pot[T.120]</th>               <td>    0.3672</td> <td>    0.079</td> <td>    4.620</td> <td> 0.000</td> <td>    0.211</td> <td>    0.523</td>
</tr>
<tr>
  <th>pot[T.180]</th>               <td>    0.2945</td> <td>    0.081</td> <td>    3.649</td> <td> 0.000</td> <td>    0.136</td> <td>    0.453</td>
</tr>
<tr>
  <th>pot[T.30]</th>                <td>    0.2980</td> <td>    0.081</td> <td>    3.696</td> <td> 0.000</td> <td>    0.140</td> <td>    0.456</td>
</tr>
<tr>
  <th>pot[T.60]</th>                <td>    0.3444</td> <td>    0.080</td> <td>    4.313</td> <td> 0.000</td> <td>    0.188</td> <td>    0.501</td>
</tr>
<tr>
  <th>water[T.50]:pot[T.120]</th>   <td>    0.1159</td> <td>    0.108</td> <td>    1.076</td> <td> 0.282</td> <td>   -0.095</td> <td>    0.327</td>
</tr>
<tr>
  <th>water[T.62.5]:pot[T.120]</th> <td>    0.0697</td> <td>    0.107</td> <td>    0.653</td> <td> 0.514</td> <td>   -0.140</td> <td>    0.279</td>
</tr>
<tr>
  <th>water[T.50]:pot[T.180]</th>   <td>    0.2906</td> <td>    0.108</td> <td>    2.697</td> <td> 0.007</td> <td>    0.079</td> <td>    0.502</td>
</tr>
<tr>
  <th>water[T.62.5]:pot[T.180]</th> <td>    0.2166</td> <td>    0.107</td> <td>    2.023</td> <td> 0.043</td> <td>    0.007</td> <td>    0.426</td>
</tr>
<tr>
  <th>water[T.50]:pot[T.30]</th>    <td>    0.0425</td> <td>    0.110</td> <td>    0.386</td> <td> 0.699</td> <td>   -0.173</td> <td>    0.258</td>
</tr>
<tr>
  <th>water[T.62.5]:pot[T.30]</th>  <td>   -0.1372</td> <td>    0.111</td> <td>   -1.241</td> <td> 0.215</td> <td>   -0.354</td> <td>    0.080</td>
</tr>
<tr>
  <th>water[T.50]:pot[T.60]</th>    <td>    0.1161</td> <td>    0.108</td> <td>    1.073</td> <td> 0.283</td> <td>   -0.096</td> <td>    0.328</td>
</tr>
<tr>
  <th>water[T.62.5]:pot[T.60]</th>  <td>    0.0902</td> <td>    0.107</td> <td>    0.842</td> <td> 0.400</td> <td>   -0.120</td> <td>    0.300</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>dispersion_1</th> <td>    2.1620</td> <td>    0.429</td> <td>    5.034</td> <td> 0.000</td> <td>    1.320</td> <td>    3.004</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>power_</th> <td>    1.0000</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>
</tr>
</tbody></table>
<table class="simpletable">
<caption>Multivariate Covariance Generalized Linear Model</caption>
<tbody><tr>
  <th>Dep. Variable:</th>    <td>viablePeas</td>    <th>  No. Iterations:    </th>     <td>3</td>    
</tr>
<tr>
  <th>Model:</th>               <td>MCGLM</td>      <th>  No. Observations:  </th>    <td>75</td>    
</tr>
<tr>
  <th>link:</th>                <td>logit</td>      <th>  Df Residuals:      </th>    <td>55</td>    
</tr>
<tr>
  <th>variance:</th>          <td>binomialP</td>    <th>  Df Model:          </th>    <td>20</td>    
</tr>
<tr>
  <th>Method:</th>        <td>Quasi-Likelihood</td> <th>  Power-fixed:       </th>   <td>True</td>   
</tr>
<tr>
  <th>Date:</th>          <td>Sun, 05 Feb 2023</td> <th>  pAIC               </th>  <td>448.02</td>  
</tr>
<tr>
  <th>Time:</th>              <td>15:16:55</td>     <th>  pBIC               </th>  <td>516.34</td>  
</tr>
<tr>
  <th> </th>                      <td> </td>        <th>  pLogLik            </th> <td>-204.0085</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                <td>   -0.8360</td> <td>    0.197</td> <td>   -4.241</td> <td> 0.000</td> <td>   -1.222</td> <td>   -0.450</td>
</tr>
<tr>
  <th>block[T.II]</th>              <td>   -0.4383</td> <td>    0.188</td> <td>   -2.329</td> <td> 0.020</td> <td>   -0.807</td> <td>   -0.069</td>
</tr>
<tr>
  <th>block[T.III]</th>             <td>   -0.1671</td> <td>    0.183</td> <td>   -0.913</td> <td> 0.361</td> <td>   -0.526</td> <td>    0.191</td>
</tr>
<tr>
  <th>block[T.IV]</th>              <td>   -0.1877</td> <td>    0.183</td> <td>   -1.023</td> <td> 0.306</td> <td>   -0.547</td> <td>    0.172</td>
</tr>
<tr>
  <th>block[T.V]</th>               <td>   -0.2926</td> <td>    0.187</td> <td>   -1.564</td> <td> 0.118</td> <td>   -0.659</td> <td>    0.074</td>
</tr>
<tr>
  <th>water[T.50]</th>              <td>    0.5675</td> <td>    0.218</td> <td>    2.603</td> <td> 0.009</td> <td>    0.140</td> <td>    0.995</td>
</tr>
<tr>
  <th>water[T.62.5]</th>            <td>    0.2414</td> <td>    0.219</td> <td>    1.102</td> <td> 0.271</td> <td>   -0.188</td> <td>    0.671</td>
</tr>
<tr>
  <th>pot[T.120]</th>               <td>   -3.3915</td> <td>    0.597</td> <td>   -5.682</td> <td> 0.000</td> <td>   -4.562</td> <td>   -2.222</td>
</tr>
<tr>
  <th>pot[T.180]</th>               <td>   -3.6309</td> <td>    0.685</td> <td>   -5.299</td> <td> 0.000</td> <td>   -4.974</td> <td>   -2.288</td>
</tr>
<tr>
  <th>pot[T.30]</th>                <td>   -1.8455</td> <td>    0.330</td> <td>   -5.600</td> <td> 0.000</td> <td>   -2.491</td> <td>   -1.200</td>
</tr>
<tr>
  <th>pot[T.60]</th>                <td>   -3.1518</td> <td>    0.541</td> <td>   -5.825</td> <td> 0.000</td> <td>   -4.212</td> <td>   -2.091</td>
</tr>
<tr>
  <th>water[T.50]:pot[T.120]</th>   <td>    0.6881</td> <td>    0.672</td> <td>    1.024</td> <td> 0.306</td> <td>   -0.629</td> <td>    2.005</td>
</tr>
<tr>
  <th>water[T.62.5]:pot[T.120]</th> <td>   -0.8359</td> <td>    0.910</td> <td>   -0.918</td> <td> 0.359</td> <td>   -2.620</td> <td>    0.948</td>
</tr>
<tr>
  <th>water[T.50]:pot[T.180]</th>   <td>    1.2731</td> <td>    0.735</td> <td>    1.732</td> <td> 0.083</td> <td>   -0.167</td> <td>    2.714</td>
</tr>
<tr>
  <th>water[T.62.5]:pot[T.180]</th> <td>    0.0683</td> <td>    0.842</td> <td>    0.081</td> <td> 0.935</td> <td>   -1.582</td> <td>    1.718</td>
</tr>
<tr>
  <th>water[T.50]:pot[T.30]</th>    <td>   -0.2773</td> <td>    0.425</td> <td>   -0.653</td> <td> 0.514</td> <td>   -1.110</td> <td>    0.555</td>
</tr>
<tr>
  <th>water[T.62.5]:pot[T.30]</th>  <td>    0.8046</td> <td>    0.400</td> <td>    2.013</td> <td> 0.044</td> <td>    0.021</td> <td>    1.588</td>
</tr>
<tr>
  <th>water[T.50]:pot[T.60]</th>    <td>    0.4598</td> <td>    0.623</td> <td>    0.739</td> <td> 0.460</td> <td>   -0.760</td> <td>    1.680</td>
</tr>
<tr>
  <th>water[T.62.5]:pot[T.60]</th>  <td>    0.6312</td> <td>    0.630</td> <td>    1.002</td> <td> 0.317</td> <td>   -0.604</td> <td>    1.866</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>dispersion_1</th> <td>    1.2970</td> <td>    0.245</td> <td>    5.294</td> <td> 0.000</td> <td>    0.817</td> <td>    1.777</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>power_</th> <td>    1.0000</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>rho_1</th> <td>    0.6373</td> <td>    0.107</td> <td>    5.930</td> <td> 0.000</td> <td>    0.427</td> <td>    0.848</td>
</tr>
<tr>
  <th>rho_2</th> <td>    0.0696</td> <td>    0.115</td> <td>    0.604</td> <td> 0.546</td> <td>   -0.156</td> <td>    0.295</td>
</tr>
<tr>
  <th>rho_3</th> <td>    0.0878</td> <td>    0.115</td> <td>    0.765</td> <td> 0.444</td> <td>   -0.137</td> <td>    0.313</td>
</tr>
</tbody></table>
</div>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>